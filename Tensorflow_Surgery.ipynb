{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tensorflow Surgery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The goal of this notebook is to explore how to remove and alter nodes in tensorflow models. Pre-trained models are great ... until you find some fatal flaw in them that prevents you from using them as you'd like (I'm looking at you 'DecodeJpeg' op that can't be run in android). This is all about taking one of those frozen or checkpointed models and picking it apart.\n",
    "\n",
    "Though this is most useful for a model you haven't made yourself (or one you simply don't want to waste the time training again), we're going to set up a basic model to use so everything that's happening will be clearer. First we'll save it, reload it after it's been saved, freeze it and reload it after it's been frozen in case you need help with those issues as well. Tensorflow doesn't exactly make them simple.\n",
    "\n",
    "Then we will load the frozen model, strip an operation out of it, save the result and run it to see the difference.\n",
    "\n",
    "Finally we'll optimize our model for inference so it is ready for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Set up basic model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First let's put two empty folders in the working directory -- one labeled \"checkpoints\" and the other \"new_checkpoints\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('checkpoints'):\n",
    "    os.mkdir('checkpoints')\n",
    "if not os.path.exists('new_checkpoints'):\n",
    "    os.mkdir('new_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is important when using interactive shells like iPython notebooks\n",
    "# If you don't reset the default graph, then tensorflow will create new\n",
    "# copies of your variables and number them like this -- \"a_1\" -- each time\n",
    "# you run a block in the notebook over again.\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholder variables\n",
    "a = tf.placeholder(tf.int16, name=\"a\")\n",
    "b = tf.placeholder(tf.int16, name=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A trainable variable\n",
    "var = tf.Variable(initial_value=16.2, name=\"var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "add = tf.add(a, b, name=\"add_ab\")\n",
    "var = tf.cast(var, tf.int16, name=\"cast_var\")\n",
    "var = tf.add(var, add, name=\"add_var\")\n",
    "mul = tf.multiply(a, var, name=\"mul_ab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are our operations. Right now the variable \"var\" (which I have entered as a float and cast into an int just to keep things interesting) gets the sum of placeholders a and b added to it and is then multiplied by a. Our goal will be to remove that \"add_var\" operation while still retaining a working graph.\n",
    "\n",
    "So the operation looks like this ...\n",
    "\n",
    "answer = a * (a + b + 16)\n",
    "\n",
    "And we want to make it this ...\n",
    "\n",
    "answer = a * 16\n",
    "\n",
    "*NOTE: \"var\" is 16 in the equation and not 16.2 because we cast it to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "model_path = './checkpoints/test_model'\n",
    "input_graph_path = './checkpoints/input_graph.pb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the purposes of this notebook we'll use a=20 and b=10. So the result of our equation as written should be ...\n",
    "\n",
    "answer = 20 * (20 + 10 + 16) = 920\n",
    "\n",
    "And after we alter our graph, it should be ...\n",
    "\n",
    "answer = 20 * 16 = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: 920\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    output = sess.run(mul, feed_dict={a: 20, b: 10})\n",
    "    \n",
    "    # Save the variables in a checkpoint and the graph in a meta graph\n",
    "    saver.save(sess, model_path, write_meta_graph=True, global_step=1)\n",
    "    \n",
    "    # Save the graph def as well.\n",
    "    # This is a bit redundant because the graph def is already contained\n",
    "    # in the meta graph we just saved but I want to use it to show you\n",
    "    # an alternative method of freezing the graph later on.\n",
    "    with open(input_graph_path, 'wb') as f:\n",
    "        f.write(sess.graph_def.SerializeToString())\n",
    "        \n",
    "    print (\"output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow saves models in three different ways:\n",
    "\n",
    "**CHECKPOINTs** store the values of your variables. The file labeled 'test_model-1.data-00000-of-00001' is the checkpoint. The other files (the plain 'checkpoint' file and the 'test_model-1.index' files) are for keeping track of which saved checkpoint is the most up-to-date.\n",
    "\n",
    "**GRAPH_DEFs** store graph operations (add, multiply, matmul, etc...) and constant values. They are saved in binary form as .pb or text form (which takes forever to load by the way for a normal-sized model) as .pbtxt. But those are just naming conventions, you decide the name yourself. In this case, the graph def is 'input_graph.pb'. Graph defs are not enough to restore a model on their own for continued training (you need variables for that) but after your model has been trained, you will convert its variables to constants and then it can be stored in a graph def. So frozen or optimized for inference models are traded around as graph def files.\n",
    "\n",
    "**META_GRAPHs** store the graph defs as well as other additional information you need to restore the model (like the SaverDef). Our Meta file appears in the checkpoints folder as 'test_model-1.meta'.\n",
    "\n",
    "When you're *training* -- you use the checkpoint and meta graph to restore the full model.\n",
    "\n",
    "For *production* -- you use a graph def with the variables frozen into constants to perform inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load and use model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's load our saved model and use it again. tf.reset_default_graph() is equivalent to us opening up a new notebook and calling these functions from there. There's no carryover from the last section (but the files we saved are still in our folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = tf.train.latest_checkpoint(\"./checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    saver = tf.train.import_meta_graph(checkpoint_path + '.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session(graph=graph)\n",
    "saver.restore(session, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Some tensorflow operations require that you append \":0\" to the\n",
    "# variables to signify that they are tensors. If you're troubleshooting\n",
    "# this is probably a good thing to try\n",
    "a = graph.get_tensor_by_name('a:0')\n",
    "b = graph.get_tensor_by_name('b:0')\n",
    "out = graph.get_tensor_by_name('mul_ab:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's take a look at the nodes in our graph_def file. This is Google's protobuf format, which serves a similar purpose to JSON. It's Google's way of efficiently representing data so programs in different languages can access it and use it easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"a\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"b\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var/initial_value\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_FLOAT\n",
      "      tensor_shape {\n",
      "      }\n",
      "      float_val: 16.200000762939453\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var\"\n",
      "op: \"VariableV2\"\n",
      "attr {\n",
      "  key: \"container\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shared_name\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var/Assign\"\n",
      "op: \"Assign\"\n",
      "input: \"var\"\n",
      "input: \"var/initial_value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"validate_shape\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var/read\"\n",
      "op: \"Identity\"\n",
      "input: \"var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"add_ab\"\n",
      "op: \"Add\"\n",
      "input: \"a\"\n",
      "input: \"b\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"cast_var\"\n",
      "op: \"Cast\"\n",
      "input: \"var/read\"\n",
      "attr {\n",
      "  key: \"DstT\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"SrcT\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"add_var\"\n",
      "op: \"Add\"\n",
      "input: \"cast_var\"\n",
      "input: \"add_ab\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"mul_ab\"\n",
      "op: \"Mul\"\n",
      "input: \"a\"\n",
      "input: \"add_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^var/Assign\"\n",
      "\n",
      "name: \"save/Const\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_STRING\n",
      "      tensor_shape {\n",
      "      }\n",
      "      string_val: \"model\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/SaveV2/tensor_names\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_STRING\n",
      "      tensor_shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      string_val: \"var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/SaveV2/shape_and_slices\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_STRING\n",
      "      tensor_shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      string_val: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/SaveV2\"\n",
      "op: \"SaveV2\"\n",
      "input: \"save/Const\"\n",
      "input: \"save/SaveV2/tensor_names\"\n",
      "input: \"save/SaveV2/shape_and_slices\"\n",
      "input: \"var\"\n",
      "attr {\n",
      "  key: \"dtypes\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/control_dependency\"\n",
      "op: \"Identity\"\n",
      "input: \"save/Const\"\n",
      "input: \"^save/SaveV2\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@save/Const\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/RestoreV2/tensor_names\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_STRING\n",
      "      tensor_shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      string_val: \"var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/RestoreV2/shape_and_slices\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_STRING\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_STRING\n",
      "      tensor_shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      string_val: \"\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/RestoreV2\"\n",
      "op: \"RestoreV2\"\n",
      "input: \"save/Const\"\n",
      "input: \"save/RestoreV2/tensor_names\"\n",
      "input: \"save/RestoreV2/shape_and_slices\"\n",
      "attr {\n",
      "  key: \"dtypes\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/Assign\"\n",
      "op: \"Assign\"\n",
      "input: \"var\"\n",
      "input: \"save/RestoreV2\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"validate_shape\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"save/restore_all\"\n",
      "op: \"NoOp\"\n",
      "input: \"^save/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_def = graph.as_graph_def()\n",
    "for node in graph_def.node:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Take a look at \"var\" -- it is labeled with the op \"VariableV2\". See if you can match the operations that are happening in protobuf to the operations in the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = session.run(out, feed_dict={a: 20, b: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: 920\n"
     ]
    }
   ],
   "source": [
    "print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load and freeze model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**TECHNIQUE #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.tools import inspect_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  var\n",
      "16.2\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = tf.train.latest_checkpoint(\"./checkpoints/\")\n",
    "inspect_checkpoint.print_tensors_in_checkpoint_file(checkpoint_path, tensor_name='', all_tensors=True)\n",
    "# Change all_tensors to False if you want it to print out just the names in the checkpoint and not\n",
    "# all the values. Typically it's better just to print the names as the values are huge matrices of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As \"var\" is our only graph variable, that's the one we'll want to freeze. Fortunately though tensorflow's utilities will figure out what variables to freeze and how on its own so we don't have to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n",
      "Converted 1 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Import our saved meta graph into the current graph we're using\n",
    "saver = tf.train.import_meta_graph(checkpoint_path + '.meta', import_scope=None)\n",
    "# If you have multiple output nodes, they should be stored as a list of strings\n",
    "# where each string is a name of one of the output nodes.\n",
    "output_node_names = \"mul_ab\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore the variable values\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    # Get the graph def from our current graph\n",
    "    graph_def = tf.get_default_graph().as_graph_def()\n",
    "    # Turn all variables into constants\n",
    "    frozen_graph_def = convert_variables_to_constants(sess, graph_def, output_node_names.split(\",\"))\n",
    "    \n",
    "    # Save our new graph def\n",
    "    with tf.gfile.GFile(\"./checkpoints/\" + \"frozen.pb\", \"wb\") as f:\n",
    "        f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It should report that 1 variable has been frozen/converted to const ops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's look at the nodes again. The op for our node \"var\" should now be changed to \"Const\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"var\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_FLOAT\n",
      "      tensor_shape {\n",
      "      }\n",
      "      float_val: 16.200000762939453\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in frozen_graph_def.node:\n",
    "    if node.name == 'var':\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**TECHNIQUE #2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This does the exact same thing but uses tensorflow's freeze_graph utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/'\n",
    "checkpoint_path = tf.train.latest_checkpoint(save_dir)\n",
    "input_graph_path = os.path.join(save_dir, 'input_graph.pb')\n",
    "meta_path = checkpoint_path + '.meta'\n",
    "output_frozen_graph_name = os.path.join(save_dir, 'frozen2.pb')\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = True\n",
    "output_node_names = \"mul_ab\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "clear_devices = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n",
      "Converted 1 variables to const ops.\n",
      "8 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                         input_binary, checkpoint_path, output_node_names,\n",
    "                         restore_op_name, filename_tensor_name,\n",
    "                         output_frozen_graph_name, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# A useful function for loading graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_graph(my_path):\n",
    "    # Load the pb file and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(my_path, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    \n",
    "    # Now import the graph_def to our default graph.\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            # If you put name=None here instead of ''\n",
    "            # it will relabel all your ops as \"import/original_name\"\n",
    "            name='',\n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    # Return the loaded graph\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load and use frozen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  920\n"
     ]
    }
   ],
   "source": [
    "filename = \"./checkpoints/\" + \"frozen.pb\"\n",
    "\n",
    "graph = load_graph(filename)\n",
    "\n",
    "a = graph.get_tensor_by_name('a:0')\n",
    "b = graph.get_tensor_by_name('b:0')\n",
    "out = graph.get_tensor_by_name('mul_ab:0')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    # Now we don't need to initialize any variables because\n",
    "    # there aren't any, only constants.\n",
    "    \n",
    "    output = sess.run(out, feed_dict={a: 20, b: 10})\n",
    "    print (\"output: \", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load graph and alter node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note that sometimes you need the './' before the address\n",
    "# and sometimes you don't. Tensorflow can be a bit fickle\n",
    "# on this point (like with adding \":0\" to tensor names)\n",
    "# so if you get an error reporting that it can't find your \n",
    "# file, this should be one of the first things you try.\n",
    "frozen_path = './checkpoints/frozen.pb'\n",
    "\n",
    "# Load our frozen graph\n",
    "graph = load_graph(frozen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check the nodes again to confirm for yourself that they've\n",
    "# been loaded correctly\n",
    "graph_def = graph.as_graph_def()\n",
    "for node in graph_def.node:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now before we get rid of \"add_var\", let's change the node that takes \"add_var\" as input and make its input the node before \"add_var\" instead, which in this case is \"cast_var\". This way we cut \"add_var\" out of the step-by-step operations of the graph entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"mul_ab\"\n",
      "op: \"Mul\"\n",
      "input: \"a\"\n",
      "input: \"cast_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in graph_def.node:\n",
    "    # Find the node that we noticed above takes \"add_var\" as input\n",
    "    if node.name == \"mul_ab\":\n",
    "        # Change its input to the node before \"add_var\"\n",
    "        node.input[1] = \"cast_var\"\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's make \"add_var\" into an identity function (an op that returns exactly what went into it). Also get rid of the second input because an identity function should only have one input.\n",
    "\n",
    "This is a workaround because in Tensorflow, you can't simply delete the node itself.\n",
    "\n",
    "There is another option. You could use export_sub_graph to recreate the graph with every node except the one you don't want. I found the approach taken in this notebook to be easier though because every time we take out a node we need to alter another one (change the input) through this process anyway whether we're using export_sub_graph or not. So we might as well finish the job with this approach.\n",
    "\n",
    "Also, assuming you will be optimizing the model for inference eventually (more info below), that process will find nodes that we've neutered and cut them out of the graph, so from a memory/final product perspective the result will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"add_var\"\n",
      "op: \"Identity\"\n",
      "input: \"cast_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in graph_def.node:\n",
    "    # Find the node we want to get rid of\n",
    "    if node.name == \"add_var\":\n",
    "        # Change its op to Identity\n",
    "        node.op = \"Identity\"\n",
    "        # Delete its second input\n",
    "        del node.input[1]\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**: If the node didn't have an attribute \"T\" already, we would have to add one as that is also a requirement of an \"Identity\" op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"a\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"b\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_FLOAT\n",
      "      tensor_shape {\n",
      "      }\n",
      "      float_val: 16.200000762939453\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var/read\"\n",
      "op: \"Identity\"\n",
      "input: \"var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@var\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"add_ab\"\n",
      "op: \"Add\"\n",
      "input: \"a\"\n",
      "input: \"b\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"cast_var\"\n",
      "op: \"Cast\"\n",
      "input: \"var/read\"\n",
      "attr {\n",
      "  key: \"DstT\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"SrcT\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"add_var\"\n",
      "op: \"Identity\"\n",
      "input: \"cast_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"mul_ab\"\n",
      "op: \"Mul\"\n",
      "input: \"a\"\n",
      "input: \"cast_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in graph_def.node:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we can see that \"add_var\" and \"mul_ab\" have been successfully changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So now we will save our new, altered frozen file in the new_checkpoints folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./new_checkpoints/altered_frozen.pb'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(graph_def, \"./new_checkpoints\", \"altered_frozen.pb\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**: I've included more info about different alterations to nodes at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph_def_path = './new_checkpoints/altered_frozen.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load our new and improved graph def\n",
    "graph = load_graph(graph_def_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = graph.get_tensor_by_name('a:0')\n",
    "b = graph.get_tensor_by_name('b:0')\n",
    "out = graph.get_tensor_by_name('mul_ab:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = session.run(out, feed_dict={a: 20, b: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the beginning we said that if our surgery is successful then the resulting answer will be 320.\n",
    "\n",
    "This means that we have successfully excised the \"add_var\" node!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Optimize for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is strictly if we want to make the model as lean as possible (useful if you want it to run on an app for instance). We could also use the altered_frozen model as is and it would work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import optimize_for_inference_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph_def_path = './new_checkpoints/altered_frozen.pb'\n",
    "optimized_model = './new_checkpoints/optimized.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the graph we just froze\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(graph_def_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    input_graph_def.ParseFromString(data)\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "        input_graph_def,\n",
    "        # A list of input nodes\n",
    "        [\"a\",\"b\"],\n",
    "        # A list of output nodes\n",
    "        [\"mul_ab\"],\n",
    "        tf.int16.as_datatype_enum)\n",
    "\n",
    "# Save the optimized graph\n",
    "f = tf.gfile.FastGFile(optimized_model, \"wb\")\n",
    "f.write(output_graph_def.SerializeToString())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"a\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"var\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_FLOAT\n",
      "      tensor_shape {\n",
      "      }\n",
      "      float_val: 16.200000762939453\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"cast_var\"\n",
      "op: \"Cast\"\n",
      "input: \"var\"\n",
      "attr {\n",
      "  key: \"DstT\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"SrcT\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"mul_ab\"\n",
      "op: \"Mul\"\n",
      "input: \"a\"\n",
      "input: \"cast_var\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT16\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in output_graph_def.node:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That got rid of unnecessary nodes like \"var/read\" and \"add_var\" (which did nothing since we turned it into an identity function.) It also removed input node \"b\" because it noticed that we are no longer using it now that our equation is just 'answer = a * var'. Thanks to the optimize_for_inference_lib we are down from a bloated 8-node graph to a lean, mean 4-node inference machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load and use optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimized_model = './new_checkpoints/optimized.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = load_graph(optimized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = graph.get_tensor_by_name('a:0')\n",
    "out = graph.get_tensor_by_name('mul_ab:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    output = sess.run(out, feed_dict={a: 20})\n",
    "    print(\"output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "sweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Other useful alterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Another common edit you might need to make to a node is to change its variable type.\n",
    "\n",
    "Let's take this node as an example:\n",
    "\n",
    "##################\n",
    "\n",
    "    name: \"input_feed\"\n",
    "    op: \"Placeholder\"\n",
    "    attr {\n",
    "      key: \"dtype\"\n",
    "      value {\n",
    "        type: DT_INT64\n",
    "        }\n",
    "    }\n",
    "##################\n",
    "\n",
    "In this node, \"input_feed\", the placeholder takes a 64-bit integer. Let's say we want to change that to a 32-bit integer.\n",
    "\n",
    "First you need to know that tensorflow protobuf files can handle 20 different types and each one has an index number. Here they are:\n",
    "\n",
    "# Variable Types\n",
    "0: DT_INVALID\n",
    "\n",
    "1: DT_FLOAT\n",
    "\n",
    "2: DT_DOUBLE\n",
    "\n",
    "3: DT_INT32\n",
    "\n",
    "4: DT_UINT8\n",
    "\n",
    "5: DT_INT16\n",
    "\n",
    "6: DT_INT8\n",
    "\n",
    "7: DT_STRING\n",
    "\n",
    "8: DT_COMPLEX64\n",
    "\n",
    "9: DT_INT64\n",
    "\n",
    "10: DT_BOOL\n",
    "\n",
    "11: DT_QINT8\n",
    "\n",
    "12: DT_QUINT8\n",
    "\n",
    "13: DT_QINT32\n",
    "\n",
    "14: DT_BFLOAT16\n",
    "\n",
    "15: DT_QINT16\n",
    "\n",
    "16: DT_QUINT16\n",
    "\n",
    "17: DT_UINT16\n",
    "\n",
    "18: DT_COMPLEX128\n",
    "\n",
    "19: DT_HALF\n",
    "\n",
    "20: DT_RESOURCE\n",
    "\n",
    "\n",
    "And here's some info on what those types represent:\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/dims_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To make the change, you just set the node's \"attr['dtype'].type\" equal to the integer label of whichever variable type you want, like so ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for node in my_graph_def.node:\n",
    "#     if node.name == \"input_feed\":\n",
    "#         # This will make it a 32-bit integer instead of 64-bit\n",
    "#         node.attr['dtype'].type = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can make other changes to the attributes of a node the same way. And you can delete attributes like this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for node in my_graph_def.node:\n",
    "#     if node.name == \"input_feed\":\n",
    "#         if 'acceptable_fraction' in node.attr: del node.attr['acceptable_fraction']\n",
    "#         if 'channels' in node.attr: del node.attr['channels']\n",
    "#         if 'fancy_upscaling' in node.attr: del node.attr['fancy_upscaling']\n",
    "#         if 'ratio' in node.attr: del node.attr['ratio']\n",
    "#         if 'try_recover_truncated' in node.attr: del node.attr['try_recover_truncated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you made a lot of alterations to the graph, it might be a good idea to check if the graph is still valid as well (meaning every op that needs an input receives one and so on).\n",
    "\n",
    "Conveniently, Tensorflow has a function for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "# optimize_for_inference_lib.ensure_graph_is_valid(my_graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That function will raise an error if the graph isn't valid. If it runs and there is no response then all is well.\n",
    "\n",
    "There are other types of errors it won't catch however that you'll only see when you run the inference operation (like a missing attribute for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
